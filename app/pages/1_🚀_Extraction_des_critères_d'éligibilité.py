import asyncio
import base64
import datetime
import io
import os

import pandas as pd
import streamlit as st
from anthropic import Anthropic
from dotenv import load_dotenv
from playwright.async_api import async_playwright
from utils.dataframe_utils import filter_dataframe
from utils.grist_utils import get_aoms_data

# from PIL import Image

load_dotenv()

st.title("Extraction des crit√®res d'√©ligibilit√©")


def ask_claude_to_extract_table_from_images(images):
    """Demande √† Claude d'extraire et structurer les donn√©es du tableau."""
    try:
        # Pr√©parer les images
        content = [
            {
                "type": "text",
                "text": (
                    "Tu es un expert en extraction de donn√©es tabulaires."
                    "Extrais les donn√©es tabulaires de ces images et "
                    "retourne-les uniquement au format CSV, sans autre texte."
                    "Ignore tout ce qui n'est pas une donn√©e tabulaire."
                ),
            }
        ]
        # Ajouter chaque image au contenu
        for image in images:
            img_byte_arr = io.BytesIO()
            image.save(img_byte_arr, format="PNG")
            image_base64 = base64.b64encode(img_byte_arr.getvalue()).decode()
            content.append(
                {
                    "type": "image",
                    "source": {
                        "type": "base64",
                        "media_type": "image/png",
                        "data": image_base64,
                    },
                }
            )
        client = Anthropic(api_key=os.environ.get("ANTHROPIC_API_KEY"))
        message = client.messages.create(
            model="claude-3-sonnet-20240229",
            max_tokens=4000,
            temperature=0,
            messages=[{"role": "user", "content": content}],
        )
        # Extraire le contenu du message
        if isinstance(message.content, list):
            for content in message.content:
                if content.type == "text":
                    return content.text
            raise ValueError("Aucun contenu texte trouv√© dans la r√©ponse")
        return message.content
    except Exception as e:
        st.error(
            f"Erreur d√©taill√©e dans ask_claude_to_extract_table: {str(e)}"
        )
        st.write("Structure de la r√©ponse:", message)
        raise


# Upload des images
# uploaded_files = st.file_uploader(
#     "Choisissez une ou plusieurs images",
#     type=["png", "jpg", "jpeg"],
#     accept_multiple_files=True,
# )
# mime = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
# if uploaded_files:
#     try:
#         # Charger toutes les images
#         images = [Image.open(file) for file in uploaded_files]
#         # Afficher les images individuelles
#         st.subheader("Images t√©l√©charg√©es")
#         cols = st.columns(min(len(images), 3))
#         for idx, (img, col) in enumerate(zip(images, cols), 1):
#             with col:
#                 st.image(img, caption=f"Image {idx}", use_column_width=True)
#         # Extraire les donn√©es des tableaux
#         csv_data = ask_claude_to_extract_table_from_images(images)
#         # Convertir en DataFrame
#         df = pd.read_csv(io.StringIO(csv_data))
#         # Afficher le r√©sultat
#         st.success("‚úÖ Donn√©es extraites avec succ√®s")
#         st.dataframe(df)
#     except Exception as e:
#         st.error(f"‚ùå Erreur lors du traitement : {str(e)}")
# else:
#     st.info("üëÜ Veuillez t√©l√©charger une ou plusieurs images")


async def scrape_aom_tarification(url, aom_name):
    """
    Scrape les informations de tarification d'une AOM √† partir de son URL.
    Args:
        url: URL de la page de tarification
        aom_name: Nom de l'AOM
    Returns:
        dict: Donn√©es structur√©es extraites au format Markdown
    """
    if not url or pd.isna(url) or url.strip() == "":
        return {"error": "URL non d√©finie pour cette AOM"}
    try:
        async with async_playwright() as p:
            # Lancer le navigateur
            browser = await p.chromium.launch(headless=True)
            page = await browser.new_page()

            # Acc√©der √† la page
            try:
                await page.goto(url, timeout=30000)
            except Exception as e:
                await browser.close()
                return {"error": f"Impossible d'acc√©der √† l'URL: {str(e)}"}

            # Capturer le contenu initial et une capture d'√©cran
            screenshot = await page.screenshot()

            # Utiliser LLM pour identifier les liens pertinents
            client = Anthropic(api_key=os.environ.get("ANTHROPIC_API_KEY"))

            # Pr√©paration du contenu pour Claude
            content_for_llm = [
                {
                    "type": "text",
                    "text": (
                        f"Analyse cette capture d'√©cran pour l'AOM {aom_name}."
                        " Identifie les liens qui pourraient contenir des "
                        " informations sur les tarifs, abonnements ou "
                        " conditions d'√©ligibilit√©. Retourne uniquement les "
                        " s√©lecteurs CSS ou XPath de ces liens, un par ligne."
                    ),
                },
                {
                    "type": "image",
                    "source": {
                        "type": "base64",
                        "media_type": "image/png",
                        "data": base64.b64encode(screenshot).decode("utf-8"),
                    },
                },
            ]

            response = client.messages.create(
                model="claude-3-sonnet-20240229",
                max_tokens=1000,
                temperature=0,
                messages=[{"role": "user", "content": content_for_llm}],
            )

            # Extraire les s√©lecteurs
            selectors = response.content[0].text.strip().split("\n")

            # Cliquer sur chaque lien identifi√© et capturer les √©crans
            all_screenshots = [
                screenshot
            ]  # Inclure la capture d'√©cran initiale
            page_titles = ["Page d'accueil"]

            for selector in selectors:
                try:
                    selector = selector.strip()
                    if not selector:
                        continue

                    # V√©rifier si le s√©lecteur existe
                    element_count = await page.evaluate(
                        f"document.querySelectorAll(`{selector}`).length"
                    )

                    if element_count == 0:
                        continue

                    # Obtenir le texte du lien pour le titre
                    link_text = await page.evaluate(
                        f"document.querySelector(`{selector}`).innerText || "
                        f"document.querySelector(`{selector}`).textContent || "
                        f"'Page de tarification'"
                    )

                    # Cliquer sur l'√©l√©ment
                    await page.click(selector)
                    await page.wait_for_load_state(
                        "networkidle", timeout=10000
                    )

                    # Capturer la page apr√®s clic
                    new_screenshot = await page.screenshot(full_page=True)
                    all_screenshots.append(new_screenshot)
                    page_titles.append(link_text.strip())

                    # Revenir √† la page pr√©c√©dente
                    await page.go_back()
                    await page.wait_for_load_state(
                        "networkidle", timeout=10000
                    )

                except Exception as e:
                    print(f"Erreur lors du clic sur {selector}: {e}")

            # Analyser les captures d'√©cran avec LLM
            final_content = [
                {
                    "type": "text",
                    "text": (
                        "Tu es un expert en extraction d'informations"
                        " tarifaires pour les transports publics.\n\n"
                        "Analyse ces captures d'√©cran pour l'AOM "
                        f"{aom_name}.\n"
                        "Extrait toutes les informations sur:\n"
                        "1. Les tarifs et abonnements\n"
                        "2. Les conditions d'√©ligibilit√© "
                        "(√¢ge, revenus, statut)\n"
                        "3. Les justificatifs requis\n\n"
                        "Pr√©sente ces informations au format Markdown bien "
                        "structur√© avec:\n"
                        "- Des titres et sous-titres clairs\n"
                        "- Des listes √† puces pour les √©l√©ments\n"
                        "- Des tableaux pour les grilles tarifaires "
                        "si n√©cessaire\n"
                        "- Des sections distinctes pour chaque type "
                        "d'information\n\n"
                        "Assure-toi que le format est propre et facile √† lire."
                    ),
                }
            ]
            # Ajouter les captures d'√©cran avec leurs titres
            for i, (screenshot, title) in enumerate(
                zip(all_screenshots[:5], page_titles[:5])
            ):
                final_content.append(
                    {
                        "type": "text",
                        "text": f"--- Capture d'√©cran {i+1}: {title} ---",
                    }
                )
                final_content.append(
                    {
                        "type": "image",
                        "source": {
                            "type": "base64",
                            "media_type": "image/png",
                            "data": base64.b64encode(screenshot).decode(
                                "utf-8"
                            ),
                        },
                    }
                )
            final_response = client.messages.create(
                model="claude-3-sonnet-20240229",
                max_tokens=4000,
                temperature=0,
                messages=[{"role": "user", "content": final_content}],
            )
            # Extraire le contenu Markdown
            markdown_content = final_response.content[0].text
            # Cr√©er un dictionnaire structur√© avec le contenu Markdown
            structured_data = {
                "markdown_content": markdown_content,
                "aom_name": aom_name,
                "source_url": url,
                "extraction_date": datetime.datetime.now().strftime(
                    "%Y-%m-%d %H:%M:%S"
                ),
            }
            await browser.close()
            return structured_data
    except Exception as e:
        return {"error": f"Erreur lors du scraping: {str(e)}"}


# Chargement initial des donn√©es
aoms_data = get_aoms_data()

# Barre de recherche
search_term = st.text_input(
    "üîç Rechercher dans toutes les colonnes",
    placeholder="Exemple : Bordeaux M√©tropole",
)

# Filtrer les donn√©es
filtered_df = filter_dataframe(aoms_data, search_term)

# Afficher le nombre de r√©sultats
nb_results = len(filtered_df)
first = f"{nb_results} r√©sultat{'s' if nb_results > 1 else ''}"
second = f"trouv√©{'s' if nb_results > 1 else ''}"

st.write(f"üìä{first} {second}")


# Afficher le tableau filtr√©
st.dataframe(
    filtered_df,
    column_config={
        "N_SIREN_AOM": "SIREN AOM",
        "Nom_de_l_AOM": "Nom de l'AOM",
        "Region": "R√©gion",
        "Page_tarification": "URL Tarification",
    },
    hide_index=True,
    use_container_width=True,
)

# S√©lection d'une AOM via une liste d√©roulante
st.subheader("S√©lectionner une AOM pour l'extraction")
aom_options = filtered_df["Nom_de_l_AOM"].tolist()
selected_aom_name = st.selectbox("Choisir une AOM", aom_options)


# R√©cup√©rer les informations de l'AOM s√©lectionn√©e
if selected_aom_name:
    selected_aom = filtered_df[
        filtered_df["Nom_de_l_AOM"] == selected_aom_name
    ].iloc[0]
    st.write(f"### AOM s√©lectionn√©e : {selected_aom['Nom_de_l_AOM']}")
    # V√©rifier si l'URL est disponible
    url_input_key = f"url_input_{selected_aom_name}"
    if (
        pd.isna(selected_aom.get("Page_tarification"))
        or selected_aom.get("Page_tarification", "").strip() == ""
    ):
        st.warning("Aucune URL de tarification n'est d√©finie pour cette AOM")
        # Demander l'URL √† l'utilisateur
        url = st.text_input(
            "Veuillez saisir l'URL du site de transport pour cette AOM:",
            key=url_input_key,
            placeholder="https://www.example.com",
        )
        if not url:
            st.info("Saisissez une URL pour continuer.")
            st.stop()
    else:
        url = selected_aom["Page_tarification"]
        # Permettre √† l'utilisateur de modifier l'URL si n√©cessaire
        url = st.text_input(
            "URL de tarification (modifiable si n√©cessaire):",
            value=url,
            key=url_input_key,
        )
    # V√©rifier que l'URL est valide
    if not url.startswith(("http://", "https://")):
        st.error("L'URL doit commencer par http:// ou https://")
        st.stop()
    # Bouton pour lancer le scraping
    col1, col2 = st.columns([1, 3])
    with col1:
        scrape_button = st.button(
            "üîç Extraire les crit√®res", use_container_width=True
        )
    if scrape_button:
        with st.spinner(
            "Extraction en cours... " "Cela peut prendre quelques instants."
        ):
            try:
                result = asyncio.run(
                    scrape_aom_tarification(url, selected_aom["Nom_de_l_AOM"])
                )
                # Afficher les r√©sultats
                if "error" in result:
                    st.error(f"‚ùå {result['error']}")
                else:
                    st.success("‚úÖ Extraction r√©ussie !")
                    # Afficher le contenu Markdown
                    st.markdown(result["markdown_content"])
                    # Informations sur la source
                    st.caption(
                        f"Source: {result['source_url']} | "
                        f"Extraction effectu√©e le {result['extraction_date']}"
                    )
                    # Option pour t√©l√©charger le contenu Markdown
                    st.download_button(
                        label="üì• T√©l√©charger au format Markdown",
                        data=result["markdown_content"],
                        file_name=f"{result['aom_name']}_tarifs.md",
                        mime="text/markdown",
                    )
            except Exception as e:
                st.error(f"‚ùå Une erreur s'est produite : {str(e)}")
                st.info("V√©rifiez que l'URL est correcte")
