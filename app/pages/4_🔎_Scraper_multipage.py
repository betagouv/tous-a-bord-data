import asyncio

import nest_asyncio
import streamlit as st

# Initialize the event loop before importing crawl4ai
# flake8: noqa: E402
nest_asyncio.apply()

from utils.crawler_utils import CrawlerManager
from utils.dataframe_utils import filter_dataframe
from utils.db_utils import load_urls_data_from_db

# Init crawler
if "crawler_manager" not in st.session_state:

    def reset_crawler_callback():
        st.session_state.crawler_manager = None

    st.session_state.crawler_manager = CrawlerManager(
        on_crawler_reset=reset_crawler_callback
    )
    st.session_state.loop = asyncio.new_event_loop()
    asyncio.set_event_loop(st.session_state.loop)


st.title("Scraper html multipage")

# Ajout des tags de mots-cl√©s
default_keywords = [
    "toutes nos offres",
    "boutique",
    "tarif",
    "tarifs",
    "abonnement",
    "solidaire",
    "titre",
    "titre et tarif",
    "tarif et titre",
    "titres et tarifs",
    "tarifs et titres",
    "tarif solidaire",
    "tarifs solidaires",
    "tarifs r√©duits",
    "tarifs √©tudiants",
    "tarifs seniors",
    "tarifs enfants",
    "tarification √©tudiant",
    "tarifs familles nombreuses",
    "tarifs personnes √† mobilit√© r√©duite",
    "tarifs PMR",
    "QF",
    "quotient familial",
    "√©tudiant",
    "√©tudiant boursiers",
    "√©tudiants",
    "√©tudiants boursiers",
    "jeunes de moins de 26 ans",
    "jeunes de moins de 25 ans",
    "jeunes actifs",
    "tarification sociale",
    "tarification solidaire",
    "tarification r√©duite",
]

if "available_keywords" not in st.session_state:
    st.session_state.available_keywords = default_keywords.copy()
if "selected_keywords" not in st.session_state:
    st.session_state.selected_keywords = default_keywords.copy()

# Ajout d'un champ pour les mots-cl√©s personnalis√©s
new_keyword = st.text_input(
    label="Ajouter un nouveau mot-cl√© :",
    placeholder="Entrez un nouveau mot-cl√© et appuyez sur Entr√©e",
    help="Le nouveau mot-cl√© sera ajout√© √† la liste des mots-cl√©s disponibles",
)
if new_keyword:
    if (
        new_keyword not in st.session_state.available_keywords
        and new_keyword not in st.session_state.selected_keywords
    ):
        st.session_state.available_keywords.append(new_keyword)
        st.session_state.selected_keywords.append(new_keyword)
        st.rerun()

# Utilisation de multiselect pour les mots-cl√©s
st.session_state.selected_keywords = st.multiselect(
    label="üè∑Ô∏è Mots-cl√©s pour la recherche :",
    options=st.session_state.available_keywords,
    default=st.session_state.selected_keywords,
    placeholder="Choisissez un ou plusieurs mots-cl√©s",
    help="S√©lectionnez les mots-cl√©s qui seront utilis√©s pour la recherche dans les urls despages web",
)

aoms_urls_data = load_urls_data_from_db()

# Barre de recherche
search_term = st.text_input(
    "üîç Rechercher une AOM",
    placeholder="Exemple : Brest M√©tropole",
)

# Filtrer les donn√©es
filtered_df = filter_dataframe(aoms_urls_data, search_term)

# Afficher le nombre de r√©sultats
nb_results = len(filtered_df)
first = f"{nb_results} r√©sultat{'s' if nb_results > 1 else ''}"
second = f"trouv√©{'s' if nb_results > 1 else ''}"

st.write(f"üìä{first} {second}")


# Afficher le tableau filtr√©

st.dataframe(
    filtered_df,
    column_config={
        "n_siren_aom": "SIREN AOM",
        "nom_aom": "Nom de l'AOM",
        "site_web_principal": "URL tarification",
        "nom_commercial": "Nom commercial",
        "exploitant": "Exploitant",
        "type_de_contrat": "Type de contrat",
        "population_aom": "Population de l'AOM",
        "nombre_membre_aom": "Nombre de membres de l'AOM",
        "surface_km_2": "Surface de l'AOM",
        "type_d_usagers_faibles_revenus": "Type d'usagers faibles revenus",
        "type_d_usagers_recherche_d_emplois": "Usagers recherche d'emplois",
    },
    hide_index=True,
    use_container_width=True,
)

# S√©lection d'une AOM via une liste d√©roulante
st.subheader("S√©lectionner une url pour l'extraction")
url_options = filtered_df["site_web_principal"].tolist()
selected_url = st.selectbox("Choisir une url", url_options)


# R√©cup√©rer les informations de l'AOM s√©lectionn√©e
if selected_url:
    selected_url = filtered_df[
        filtered_df["site_web_principal"] == selected_url
    ].iloc[0]
    url = selected_url["site_web_principal"]
    if not url.startswith(("http://", "https://")):
        st.error("L'URL doit commencer par http:// ou https://")
        st.stop()
    scrape_button = st.button(
        "üîç Extraire les informations de tarification", use_container_width=True
    )


if scrape_button:
    keywords = st.session_state.selected_keywords

    with st.spinner(
        "Extraction en cours... " "Cela peut prendre quelques instants."
    ):
        try:
            loop = st.session_state.loop
            asyncio.set_event_loop(loop)
            results = loop.run_until_complete(
                st.session_state.crawler_manager.fetch_content(url, keywords)
            )
            # Cr√©er un onglet par page
            tabs = st.tabs([f"Page {i+1}" for i in range(len(results))])

            for i, page in enumerate(results):
                with tabs[i]:
                    st.markdown(f"{page.url}")
                    st.markdown(page.markdown)
        except Exception as e:
            st.error(f"‚ùå Une erreur s'est produite : {str(e)}")
