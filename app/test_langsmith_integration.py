#!/usr/bin/env python3
"""
Script de test pour vÃ©rifier l'intÃ©gration LangSmith
"""

import os
import sys

from dotenv import load_dotenv

# Charger les variables d'environnement
load_dotenv()


def test_environment_variables():
    """Teste que toutes les variables d'environnement nÃ©cessaires
    sont dÃ©finies"""
    print("ğŸ” VÃ©rification des variables d'environnement...")

    required_vars = [
        "LANGCHAIN_TRACING_V2",
        "LANGCHAIN_API_KEY",
        "LANGCHAIN_PROJECT",
    ]

    missing_vars = []
    for var in required_vars:
        value = os.getenv(var)
        if not value:
            missing_vars.append(var)
        else:
            # Masquer la clÃ© API pour la sÃ©curitÃ©
            if "API_KEY" in var:
                display_value = value[:8] + "..." if len(value) > 8 else "***"
            else:
                display_value = value
            print(f"  âœ… {var} = {display_value}")

    if missing_vars:
        print(f"  âŒ Variables manquantes : {', '.join(missing_vars)}")
        return False

    print("  âœ… Toutes les variables d'environnement sont dÃ©finies")
    return True


def test_langsmith_connection():
    """Teste la connexion Ã  LangSmith"""
    print("\nğŸ”— Test de connexion Ã  LangSmith...")

    try:
        from services.evaluation_service import evaluation_service

        # Tester la connexion en rÃ©cupÃ©rant les statistiques
        stats = evaluation_service.get_evaluation_stats()
        print("  âœ… Connexion rÃ©ussie Ã  LangSmith")
        print(f"  ğŸ“Š Projet : {evaluation_service.project_name}")
        print(f"  ğŸ“ˆ Runs totaux : {stats['total_runs']}")
        return True

    except Exception as e:
        print(f"  âŒ Erreur de connexion : {str(e)}")
        return False


def test_llm_services():
    """Teste que les services LLM ont bien les dÃ©corateurs @traceable"""
    print("\nğŸ¤– VÃ©rification des services LLM...")

    try:
        from services.llm_services import (
            call_anthropic,
            call_ollama,
            call_scaleway,
        )

        # VÃ©rifier que les fonctions ont l'attribut __wrapped__
        # (signe du dÃ©corateur)
        services = [
            ("call_anthropic", call_anthropic),
            ("call_scaleway", call_scaleway),
            ("call_ollama", call_ollama),
        ]

        for name, func in services:
            if hasattr(func, "__wrapped__"):
                print(f"  âœ… {name} : dÃ©corateur @traceable dÃ©tectÃ©")
            else:
                print(f"  âš ï¸ {name} : dÃ©corateur @traceable manquant")

        return True

    except ImportError as e:
        print(f"  âŒ Erreur d'import : {str(e)}")
        return False


def test_simple_llm_call():
    """Teste un appel LLM simple pour vÃ©rifier le tracking"""
    print("\nğŸ§ª Test d'appel LLM avec tracking...")

    try:
        from services.llm_services import call_ollama

        # Test simple avec Ollama (le plus accessible)
        print("  ğŸ”„ Test d'appel Ollama...")

        # Appel simple qui devrait Ãªtre trackÃ©
        prompt = "Dis bonjour en franÃ§ais en une phrase."

        # Note: Cet appel peut Ã©chouer si Ollama n'est pas disponible
        # mais l'important est de vÃ©rifier que le tracking fonctionne
        try:
            response = call_ollama(prompt, model="llama3:8b")
            print(f"  âœ… Appel rÃ©ussi : {response[:50]}...")
        except Exception as e:
            error_msg = (
                f"  âš ï¸ Appel Ã©chouÃ© (normal si Ollama non disponible) : "
                f"{str(e)}"
            )
            print(error_msg)
            print("  â„¹ï¸ L'important est que le tracking soit configurÃ©")

        return True

    except Exception as e:
        print(f"  âŒ Erreur lors du test : {str(e)}")
        return False


def main():
    """Fonction principale de test"""
    print("ğŸš€ Test d'intÃ©gration LangSmith pour le pipeline RAG Transport")
    print("=" * 60)

    tests = [
        test_environment_variables,
        test_langsmith_connection,
        test_llm_services,
        test_simple_llm_call,
    ]

    results = []
    for test in tests:
        try:
            result = test()
            results.append(result)
        except Exception as e:
            print(f"  âŒ Erreur inattendue : {str(e)}")
            results.append(False)

    print("\n" + "=" * 60)
    print("ğŸ“‹ RÃ©sumÃ© des tests :")

    test_names = [
        "Variables d'environnement",
        "Connexion LangSmith",
        "Services LLM",
        "Appel LLM trackÃ©",
    ]

    for i, (name, result) in enumerate(zip(test_names, results)):
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"  {i+1}. {name}: {status}")

    success_rate = sum(results) / len(results)
    print(f"\nğŸ¯ Taux de rÃ©ussite : {success_rate:.1%}")

    if success_rate == 1.0:
        print(
            "ğŸ‰ Tous les tests sont passÃ©s ! L'intÃ©gration LangSmith "
            "est prÃªte."
        )
    elif success_rate >= 0.5:
        print("âš ï¸ Certains tests ont Ã©chouÃ©. VÃ©rifiez la configuration.")
    else:
        print("âŒ La plupart des tests ont Ã©chouÃ©. VÃ©rifiez la documentation.")

    print("\nğŸ“š Pour plus d'aide, consultez CONFIGURATION_LANGSMITH.md")

    return success_rate == 1.0


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
