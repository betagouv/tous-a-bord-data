import asyncio
import os
from datetime import datetime
from typing import Dict, List

import nest_asyncio

# Initialize the event loop before importing crawl4ai
# flake8: noqa: E402
nest_asyncio.apply()

import streamlit as st
import tiktoken
from dotenv import load_dotenv
from langsmith import traceable
from langsmith.run_helpers import get_current_run_tree
from star_ratings import star_ratings
from streamlit_tags import st_tags

from constants.keywords import DEFAULT_KEYWORDS
from services.evaluation_service import evaluation_service

# Import pour l'√©valuation HITL
from services.grist_service import GristDataService
from services.llm_services import LLM_MODELS

# Import pour la classification TSST
from services.tsst_spacy_llm_task import TSSTClassifier
from utils.crawler_utils import CrawlerManager

load_dotenv()


async def get_aom_transport_offers():
    try:
        # Get GristDataService instance
        grist_service = GristDataService.get_instance(
            api_key=os.getenv("GRIST_API_KEY")
        )
        doc_id = os.getenv("GRIST_DOC_INTERMEDIARY_ID")
        aoms = await grist_service.get_aom_transport_offers(doc_id)
        return aoms
    except Exception as e:
        st.error(f"Erreur lors de la connexion √† Grist : {str(e)}")
        return []


@traceable
def extract_content(url_source, keywords):
    """
    Extract content from a URL using the crawler.

    Args:
        url_source: The URL to crawl
        keywords: List of keywords to search for

    Returns:
        List of pages with extracted content
    """
    run = get_current_run_tree()
    st.session_state.run_ids["scraping"] = run.id
    try:
        # WARNING: when launch a crawler in streamlit
        # we need a single event loop
        loop = st.session_state.loop
        asyncio.set_event_loop(loop)

        # R√©utiliser la m√™me instance de CrawlerManager
        crawler_manager = CrawlerManager()

        pages = loop.run_until_complete(
            crawler_manager.fetch_content(
                url_source,
                keywords,
            )
        )
        return pages
    except Exception as e:
        st.error(f"Erreur lors de l'extraction du contenu : {str(e)}")
        return []


def count_tokens(text: str) -> int:
    """Compte le nombre de tokens dans un texte (version g√©n√©rale)"""
    # Utiliser cl100k comme tokenizer g√©n√©ral
    return len(tiktoken.encoding_for_model("gpt-3.5-turbo").encode(text))


@traceable
def filter_nlp(
    content: str,
) -> Dict[str, str]:
    """Filtre le contenu avec SpaCy"""
    try:
        run = get_current_run_tree()
        st.session_state.run_ids["filter"] = run.id
        from services.nlp_services import (
            extract_markdown_text,
            filter_transport_fare,
            load_spacy_model,
            normalize_text,
        )

        with st.spinner("Analyse automatique du langage naturel..."):
            nlp = load_spacy_model()
            raw_text = extract_markdown_text(content)
            paragraphs = normalize_text(raw_text, nlp)
            paragraphs_filtered, _ = filter_transport_fare(paragraphs, nlp)
            filtered = "\n\n".join(paragraphs_filtered)

            if filtered:
                return {"Contenu filtr√©": filtered}
            else:
                return {"Contenu filtr√©": ""}
    except Exception as e:
        st.error(f"Erreur de filtrage NLP : {str(e)}")
        return {"Contenu filtr√©": f"Erreur lors du filtrage NLP : {str(e)}"}


def check_transport_fare_content(text: str) -> tuple[bool, list]:
    """V√©rifie si le contenu contient des informations sur les tarifs de transport

    Returns:
        tuple: (has_fares, fare_matches) o√π has_fares est un bool√©en indiquant si des tarifs ont √©t√© trouv√©s
               et fare_matches est une liste des correspondances avec leur contexte
    """
    from services.nlp_services import (
        create_transport_fare_matcher,
        load_spacy_model,
    )

    nlp = load_spacy_model()
    doc = nlp(text)

    # Utiliser le matcher de tarifs de transport
    matcher = create_transport_fare_matcher(nlp)

    # V√©rifier s'il y a des correspondances
    matches_regex = matcher(doc)

    # Pr√©parer les informations sur les correspondances pour affichage ult√©rieur
    fare_matches = []

    for match_id, start, end in matches_regex:
        match_type = nlp.vocab.strings[match_id]
        matched_text = doc[start:end].text

        # Trouver la phrase contenant la correspondance
        sent = None
        for s in doc.sents:
            if start >= s.start and end <= s.end:
                sent = s
                break

        match_info = {
            "type": match_type,
            "text": matched_text,
            "context": None,
        }

        if sent:
            # Pr√©parer le contexte avec le texte mis en √©vidence
            before = sent.text[: doc[start].idx - sent.start_char]
            match = matched_text
            after = sent.text[
                doc[end - 1].idx + len(doc[end - 1].text) - sent.start_char :
            ]

            match_info["context"] = {
                "before": before,
                "match": match,
                "after": after,
            }

        fare_matches.append(match_info)

    # Si on trouve au moins une correspondance, le contenu contient des informations sur les tarifs
    return len(matches_regex) > 0, fare_matches


@traceable
def format_tags_and_providers(
    text: str, siren: str, name: str
) -> tuple[List[str], List[str]]:
    """Extrait les tags ET les fournisseurs en une seule fois optimis√©e"""
    run = get_current_run_tree()
    st.session_state.run_ids["format_tags_and_providers"] = run.id
    from services.nlp_services import (
        extract_tags_and_providers,
        load_spacy_model,
    )

    nlp = load_spacy_model()

    # UNE SEULE extraction pour tout
    tags, providers, tags_debug, providers_debug = extract_tags_and_providers(
        text, nlp, siren, name
    )

    # Stocker les explications dans session_state
    if tags_debug:
        st.session_state.tags_explanations = {
            "title": "### ‚ÑπÔ∏è Explications des tags d√©tect√©s",
            "matches": {
                tag: match_info
                for tag, match_info in tags_debug.items()
                if tag is not None
            },
        }

    if providers_debug:
        st.session_state.providers_explanations = {
            "title": "### ‚ÑπÔ∏è Explications des fournisseurs d√©tect√©s",
            "matches": {
                provider: match_info
                for provider, match_info in providers_debug.items()
                if provider is not None
            },
        }

    return tags, providers


def show_evaluation_interface(step_name: str) -> None:
    """Affiche l'interface d'√©valuation pour une √©tape"""
    st.subheader("‚ú® √âvaluation")

    # Score avec star_ratings
    stars = star_ratings("√âvaluation", numStars=5, key=f"stars_{step_name}")
    quality_score = stars / 5 if stars is not None else 0

    # Commentaire
    correction = st.text_area(
        "Commentaire (optionnel)",
        placeholder="Proposez une version corrig√©e du r√©sultat...",
        key=f"correction_{step_name}",
    )

    # Bouton de sauvegarde
    if st.button("üíæ Sauvegarder l'√©valuation", key=f"save_{step_name}"):
        with st.spinner("Sauvegarde de l'√©valuation..."):
            run_id = st.session_state.run_ids.get(step_name)
            if not run_id:
                st.error(f"‚ùå Pas de run_id trouv√© pour l'√©tape {step_name}")
                return

            feedback = evaluation_service.create_feedback(
                run_id=run_id,
                key="quality",
                score=quality_score,
                correction=correction,
            )
            if feedback:
                st.success("‚úÖ √âvaluation sauvegard√©e !")
            else:
                st.error("‚ùå Erreur lors de la sauvegarde")


# UI
st.set_page_config(
    page_title="Tags extraction - pipeline", layout="wide", page_icon="üè∑Ô∏è"
)
st.header("üè∑Ô∏è Tags extraction - pipeline")
st.subheader("S√©lection de l'AOM")

# init run_ids for evaluation
if "run_ids" not in st.session_state:
    st.session_state.run_ids = {}

# init crawler event loop
if "loop" not in st.session_state:
    st.session_state.loop = asyncio.new_event_loop()


aoms = asyncio.run(get_aom_transport_offers())

selected_aom = st.selectbox(
    "S√©lectionner une AOM:",
    options=[aom.n_siren_groupement for aom in aoms],
    format_func=lambda x: (
        f"{x} - "
        f"{next((a.nom_aom for a in aoms if a.n_siren_groupement == x), 'Unknown')} "
        f"({sum(1 for a in aoms if a.n_siren_groupement == x and a.site_web_principal)} source"
        f"{'s' if sum(1 for a in aoms if a.n_siren_groupement == x and a.site_web_principal) > 1 else ''})"
    ),
    key="selected_aom",
    on_change=lambda: (
        # Nettoyer toutes les donn√©es de session quand on change d'AOM
        st.session_state.pop("raw_scraped_content", None),
        st.session_state.pop("scraped_content", None),
        st.session_state.pop("filtered_contents", None),
        st.session_state.pop(
            "tsst_classification_result", None
        ),  # R√©initialiser la classification TSST
        st.session_state.pop("tags", None),
        st.session_state.pop("providers", None),
        st.session_state.pop(
            "tags_explanations", None
        ),  # Ajout de cette ligne
        st.session_state.pop(
            "providers_explanations", None
        ),  # Ajout de cette ligne
        st.session_state.pop("run_ids", {}),  # R√©initialiser les run_ids
        # R√©initialiser les variables de d√©tection de changement de mod√®le
        st.session_state.pop("previous_model_name", None),
        st.session_state.pop("model_changed", None),
    ),
)

if selected_aom:
    n_siren_aom = next(
        (a.n_siren_aom for a in aoms if a.n_siren_groupement == selected_aom),
        None,
    )
    nom_aom = next(
        (a.nom_aom for a in aoms if a.n_siren_groupement == selected_aom),
        "Nom inconnu",
    )
    # Collect all site_web_principal values for this AOM
    sources = " | ".join(
        [
            a.site_web_principal
            for a in aoms
            if a.n_siren_groupement == selected_aom and a.site_web_principal
        ]
    )
    st.write("Sources pour cet AOM:")
    for source in sources.split(" | "):
        if source:  # Only display non-empty sources
            st.write(f"- {source}")

    # Step 1: Scraping
    if "available_keywords" not in st.session_state:
        st.session_state.available_keywords = DEFAULT_KEYWORDS.copy()
    if "selected_keywords" not in st.session_state:
        st.session_state.selected_keywords = DEFAULT_KEYWORDS.copy()

    with st.expander("üï∏Ô∏è Task 1 : Scraper le contenu"):
        new_keyword = st.text_input(
            "Ajouter un nouveau mot-cl√© :",
            placeholder="Entrez un nouveau mot-cl√© et appuyez sur Entr√©e",
            help="Le nouveau mot-cl√© sera ajout√© √† la liste disponible",
        )

        if new_keyword:
            if new_keyword not in st.session_state.available_keywords:
                st.session_state.available_keywords.append(new_keyword)
                st.session_state.selected_keywords.append(new_keyword)
                st.rerun()

        selected_keywords = st.multiselect(
            "Mots-cl√©s :",
            options=st.session_state.available_keywords,
            default=st.session_state.selected_keywords,
        )
        start_button = st.button(
            "üï∑Ô∏è Lancer l'extraction",
            help="Cliquez pour lancer l'extraction des donn√©es sur les sites web",
        )
        if start_button:
            st.session_state.raw_scraped_content = {}
            for url_source in sources.split(" | "):
                st.session_state.raw_scraped_content[url_source] = []
                pages = extract_content(
                    url_source, st.session_state.selected_keywords
                )

                # Ajouter les pages √† la liste globale
                for page in pages:
                    st.session_state.raw_scraped_content[url_source].append(
                        {
                            "url": page.url,
                            "markdown": page.markdown,
                        }
                    )
            st.success("‚úÖ Extraction termin√©e")

    # Step 2: Affichage du contenu scrap√©
    with st.expander("üëÄ Task 2 : Afficher le contenu scrap√©"):
        if "raw_scraped_content" in st.session_state:

            # Utiliser les donn√©es en session
            sources = st.session_state.raw_scraped_content

            # Pr√©parer le contenu total pour compter les tokens
            scraped_content = ""
            for pages in sources.values():
                for page in pages:
                    scraped_content += (
                        f"--- Page: {page['url']} ---\n{page['markdown']}\n\n"
                    )

            nb_tokens = count_tokens(scraped_content)
            st.write(f"Nombre de tokens : {nb_tokens}")

            total_pages = sum(len(pages) for pages in sources.values())

            # V√©rifier s'il y a au moins une page avant de cr√©er les onglets
            if total_pages > 0:
                tabs = st.tabs([f"Page {i+1}" for i in range(total_pages)])

                # Compteur pour suivre l'index de l'onglet actuel
                tab_index = 0

                # Parcourir chaque source et ses pages
                for i, (url_source, pages) in enumerate(sources.items()):
                    # Afficher chaque page de la source dans un onglet distinct
                    for page in pages:
                        with tabs[tab_index]:
                            st.write(f"Source {i+1}")
                            st.write(
                                f"Date d'extraction: {datetime.now().strftime('%Y-%m-%d')}"
                            )
                            st.write(f"URL source: {url_source}")
                            st.write(f"URL: {page['url']}")
                            st.markdown(page["markdown"])
                        tab_index += 1
            else:
                st.warning(
                    "‚ö†Ô∏è Aucune page n'a √©t√© extraite. Essayez de relancer l'extraction ou de choisir une autre AOM."
                )

            # Sauvegarder dans session_state pour les √©tapes suivantes
            st.session_state.scraped_content = scraped_content

    # Step 3: Filtrage du contenu
    with st.expander("üéØ Task 3 : Filtrage du contenu"):
        # V√©rifier si l'√©tape pr√©c√©dente est compl√©t√©e
        is_previous_step_complete = (
            "scraped_content" in st.session_state
            and st.session_state.scraped_content
        )

        if not is_previous_step_complete:
            st.warning("‚ö†Ô∏è Veuillez d'abord compl√©ter l'√©tape de scraping")

        # Afficher le contenu filtr√© s'il existe
        if "filtered_contents" in st.session_state:
            filtered_content = st.session_state.filtered_contents[
                "Contenu filtr√©"
            ]
            has_fares, fare_matches = check_transport_fare_content(
                filtered_content
            )
            # Stocker les r√©sultats dans la session pour affichage apr√®s le spinner
            st.session_state.fare_check_result = {
                "has_fares": has_fares,
                "fare_matches": fare_matches,
            }
            nb_tokens = count_tokens(filtered_content)

            st.text_area(
                label=f"Contenu filtr√© (NLP) - {nb_tokens} tokens",
                value=filtered_content,
                height=500,
                disabled=True,
            )
            if not has_fares:
                st.error(
                    "‚ö†Ô∏è Aucune information sur les tarifs de transport n'a √©t√© d√©tect√©e dans le contenu filtr√©."
                )
                show_evaluation_interface("filter")
                st.stop()

            show_evaluation_interface("filter")

        if st.button(
            "Lancer le filtrage",
            key="filter_content",
            disabled=not is_previous_step_complete,
        ):
            # V√©rification du contenu une seule fois
            scraped_content = st.session_state.get("scraped_content", {})
            if not scraped_content:
                st.error("Veuillez d'abord charger le contenu dans l'√©tape 2")
                st.stop()
            filtered_result = filter_nlp(scraped_content)
            if filtered_result["Contenu filtr√©"].strip():
                st.session_state.filtered_contents = filtered_result
                st.success("Filtrage termin√©")
                st.rerun()
            else:
                st.error("Aucun contenu pertinent trouv√© dans les sources")

    with st.expander("ü§ñ Task 4 : Classification TSST avec LLM"):
        # V√©rifier si l'√©tape pr√©c√©dente est compl√©t√©e
        is_previous_step_complete = (
            "filtered_contents" in st.session_state
            and st.session_state.filtered_contents.get(
                "Contenu filtr√©", ""
            ).strip()
        )

        if not is_previous_step_complete:
            st.warning("‚ö†Ô∏è Veuillez d'abord compl√©ter l'√©tape de filtrage")

        # Fonction pour d√©tecter le changement de mod√®le
        def on_model_change():
            if (
                "previous_model_name" in st.session_state
                and st.session_state.selected_model_name
                != st.session_state.previous_model_name
            ):
                # R√©initialiser le r√©sultat de classification si le mod√®le change
                st.session_state.pop("tsst_classification_result", None)
                st.session_state.model_changed = (
                    True  # Set this to True when model changes
                )
                st.session_state.previous_model_name = (
                    st.session_state.selected_model_name
                )

        # Initialiser les variables de session si elles n'existent pas
        if "previous_model_name" not in st.session_state:
            st.session_state.previous_model_name = list(LLM_MODELS.keys())[0]
        if "model_changed" not in st.session_state:
            st.session_state.model_changed = False

        # S√©lecteur de mod√®le LLM avec d√©tection de changement
        selected_model_name = st.selectbox(
            "Mod√®le LLM √† utiliser",
            options=list(LLM_MODELS.keys()),
            index=0,
            key="selected_model_name",
            on_change=on_model_change,
        )

        # Afficher le r√©sultat de la classification TSST s'il existe
        if "tsst_classification_result" in st.session_state:
            result = st.session_state.tsst_classification_result

            st.subheader("R√©sultat de la classification TSST")

            if result["is_tsst"]:
                st.success(
                    "‚úÖ Le contenu concerne la tarification sociale et solidaire des transports (TSST)"
                )
            else:
                st.error(
                    "‚ùå Le contenu ne concerne PAS la tarification sociale et solidaire des transports"
                )
                show_evaluation_interface("tsst_classification")
                st.stop()

            # Afficher la justification si disponible
            if "justification" in result and result["justification"]:
                st.markdown("**Justification:**")
                st.info(result["justification"])

            # Cr√©er un conteneur pour les d√©tails techniques
            st.markdown("**D√©tails techniques:**")
            col1, col2 = st.columns(2)

            st.markdown("**R√©ponse du LLM:**")
            st.code(result["response"], language="text")

            # Ajouter l'interface d'√©valuation
            show_evaluation_interface("tsst_classification")

        @traceable
        def classify_tsst(content: str, model_name: str) -> Dict:
            """Classifie le contenu pour d√©terminer s'il concerne la TSST"""
            run = get_current_run_tree()
            st.session_state.run_ids["tsst_classification"] = run.id

            # Initialiser le classifieur TSST
            classifier = TSSTClassifier(model_name=model_name)

            # Classifier le contenu entier
            is_tsst, details = classifier.classify_paragraph(content)

            # Pr√©parer le r√©sultat
            result = {
                "is_tsst": is_tsst,
                "scores": details["scores"],
                "prompt": details["prompt"],
                "response": details["response"],
                "justification": details.get("justification", ""),
            }

            return result

        if st.button(
            "Lancer la classification TSST",
            key="tsst_classification",
            disabled=not is_previous_step_complete,
        ):
            # V√©rification du contenu filtr√©
            filtered_content = st.session_state.filtered_contents.get(
                "Contenu filtr√©", ""
            ).strip()
            if not filtered_content:
                st.error("Le contenu filtr√© est vide")
                st.stop()
            with st.spinner("Classification TSST en cours..."):
                try:
                    # Appeler la fonction tra√ßable
                    result = classify_tsst(
                        filtered_content, selected_model_name
                    )
                    # Stocker le r√©sultat dans la session
                    st.session_state.tsst_classification_result = result
                    st.success("Classification TSST termin√©e")
                    st.rerun()
                except Exception as e:
                    st.error(
                        f"Erreur lors de la classification TSST: {str(e)}"
                    )

    with st.expander(
        "üè∑Ô∏è Task 5 : Extraction des tags et fournisseurs", expanded=True
    ):
        # V√©rifier si la classification TSST est activ√©e et disponible
        tsst_enabled = "tsst_classification_result" in st.session_state

        # V√©rifier si l'√©tape pr√©c√©dente est compl√©t√©e
        is_previous_step_complete = (
            "filtered_contents" in st.session_state
            and st.session_state.filtered_contents.get(
                "Contenu filtr√©", ""
            ).strip()
        )

        # Si la classification TSST est activ√©e mais le r√©sultat est n√©gatif, bloquer l'extraction
        if (
            tsst_enabled
            and not st.session_state["tsst_classification_result"]["is_tsst"]
        ):
            st.error(
                "‚ùå Le contenu ne concerne pas la tarification sociale et solidaire des transports. L'extraction des tags est d√©sactiv√©e."
            )
            is_previous_step_complete = False
            st.stop()
        elif not is_previous_step_complete:
            st.warning("‚ö†Ô∏è Veuillez d'abord compl√©ter l'√©tape de filtrage")

        # Cr√©er un conteneur pour le bouton d'extraction
        extraction_container = st.container()
        with extraction_container:
            if st.button(
                "Extraire les tags et fournisseurs",
                key="format_tags_and_providers",
                use_container_width=True,
                disabled=not is_previous_step_complete,
            ):
                with st.spinner("Extraction en cours..."):
                    # V√©rifier d'abord si le contenu contient des informations sur les tarifs
                    filtered_content = st.session_state.filtered_contents[
                        "Contenu filtr√©"
                    ].strip()

                    # UNE SEULE extraction pour tout
                    tags, providers = format_tags_and_providers(
                        filtered_content,
                        n_siren_aom,
                        nom_aom,
                    )
                    st.session_state.tags = tags
                    st.session_state.providers = providers
                    st.rerun()

                # Afficher les r√©sultats de la v√©rification des tarifs (ce code ne sera ex√©cut√© qu'apr√®s le spinner)
                if "fare_check_result" in st.session_state:
                    result = st.session_state.fare_check_result

                    st.subheader(
                        "D√©tails des correspondances de tarifs d√©tect√©es"
                    )

                    if result["has_fares"]:
                        st.success(
                            f"‚úÖ {len(result['fare_matches'])} correspondances de tarifs trouv√©es"
                        )

                        for match in result["fare_matches"]:
                            st.markdown(f"**Type de tarif**: {match['type']}")
                            st.markdown(f"**Texte d√©tect√©**: {match['text']}")

                            if match["context"]:
                                context = match["context"]
                                st.markdown(
                                    f"**Contexte**: {context['before']}<mark style='background-color: #FFFF00'>{context['match']}</mark>{context['after']}",
                                    unsafe_allow_html=True,
                                )

                            st.markdown("---")
                    else:
                        st.warning(
                            "‚ö†Ô∏è Aucune correspondance de tarif trouv√©e dans le texte"
                        )

        # Cr√©er des onglets pour organiser le contenu
        if (
            "tags" in st.session_state
            or "providers" in st.session_state
            or "fare_check_result" in st.session_state
        ):
            tabs = st.tabs(
                [
                    "Tags d√©tect√©s",
                    "Fournisseurs d√©tect√©s",
                    "Tarifs d√©tect√©s",
                    "√âvaluation",
                ]
            )

            # Onglet des tags
            with tabs[0]:
                if "tags" in st.session_state:
                    st.markdown("### üè∑Ô∏è Tags d√©tect√©s")
                    st.session_state.tags = st_tags(
                        label="",
                        text="",
                        value=st.session_state.tags,
                        key="tag_display",
                    )

                    # Explications des tags
                    if "tags_explanations" in st.session_state:
                        st.markdown("#### ‚ÑπÔ∏è Explications des tags d√©tect√©s")
                        # Cr√©er un conteneur HTML scrollable
                        explanation_html = "<div class='scrollable-container'>"
                        for (
                            tag,
                            match_info,
                        ) in st.session_state.tags_explanations[
                            "matches"
                        ].items():
                            explanation_html += (
                                f"<p><strong>{tag}</strong> d√©tect√© dans :</p>"
                            )
                            explanation_html += f"{match_info}<hr>"
                        explanation_html += "</div>"
                        # Utiliser components.v1.html au lieu de markdown
                        st.components.v1.html(
                            explanation_html, height=400, scrolling=True
                        )

            # Onglet des fournisseurs
            with tabs[1]:
                if "providers" in st.session_state:
                    st.markdown("### üìä Fournisseurs d√©tect√©s")
                    st.session_state.providers = st_tags(
                        label="",
                        text="",
                        value=st.session_state.providers,
                        key="provider_display",
                    )

                    # Explications des fournisseurs
                    if "providers_explanations" in st.session_state:
                        st.markdown(
                            "#### ‚ÑπÔ∏è Explications des fournisseurs d√©tect√©s"
                        )
                        # Cr√©er un conteneur HTML scrollable
                        explanation_html = "<div class='scrollable-container'>"
                        for (
                            provider,
                            match_info,
                        ) in st.session_state.providers_explanations[
                            "matches"
                        ].items():
                            explanation_html += f"<p><strong>{provider}</strong> d√©tect√© dans :</p>"
                            explanation_html += f"{match_info}<hr>"
                        explanation_html += "</div>"
                        # Utiliser components.v1.html au lieu de markdown
                        st.components.v1.html(
                            explanation_html, height=400, scrolling=True
                        )

            # Onglet des tarifs d√©tect√©s
            with tabs[2]:
                if "fare_check_result" in st.session_state:
                    result = st.session_state.fare_check_result

                    st.markdown("### üí∞ Tarifs d√©tect√©s")

                    if result["has_fares"]:
                        st.success(
                            f"‚úÖ {len(result['fare_matches'])} correspondances de tarifs trouv√©es"
                        )

                        for match in result["fare_matches"]:
                            st.markdown(f"**Type de tarif**: {match['type']}")
                            st.markdown(f"**Texte d√©tect√©**: {match['text']}")

                            if match["context"]:
                                context = match["context"]
                                st.markdown(
                                    f"**Contexte**: {context['before']}<mark style='background-color: #FFFF00'>{context['match']}</mark>{context['after']}",
                                    unsafe_allow_html=True,
                                )

                            st.markdown("---")
                    else:
                        st.warning(
                            "‚ö†Ô∏è Aucune correspondance de tarif trouv√©e dans le texte"
                        )

            # Onglet d'√©valuation
            with tabs[3]:
                if (
                    "tags" in st.session_state
                    and "providers" in st.session_state
                ):
                    show_evaluation_interface("format_tags_and_providers")
